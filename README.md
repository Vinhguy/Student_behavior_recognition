<h1 align="center">NHáº¬N DIá»†N HÃ€NH VI Cá»¦A SINH VIÃŠN TRONG Lá»šP Há»ŒC </h1>

<div align="center">

<p align="center">
  <img src="./anhimage/logodnu.webp" alt="DaiNam University Logo" width="200"/>
    <img src="./anhimage/LogoAIoTLab.png" alt="AIoTLab Logo" width="170"/>
</p>

[![Made by AIoTLab](https://img.shields.io/badge/Made%20by%20AIoTLab-blue?style=for-the-badge)](https://www.facebook.com/DNUAIoTLab)
[![Fit DNU](https://img.shields.io/badge/Fit%20DNU-green?style=for-the-badge)](https://fitdnu.net/)
[![DaiNam University](https://img.shields.io/badge/DaiNam%20University-red?style=for-the-badge)](https://dainam.edu.vn)
</div>

<h2 align="center">Sá»­ Dá»¥ng Yolov8 Äá»ƒ Nháº­n Diá»‡n HÃ nh Vi Cá»§a Sinh ViÃªn</h2>

<p align="left">
  Nháº­n diá»‡n hÃ nh vi há»c sinh trong lá»›p há»c sá»­ dá»¥ng YOLOv8 lÃ  á»©ng dá»¥ng cÃ´ng nghá»‡ AI Ä‘á»ƒ phÃ¡t hiá»‡n hÃ nh vi nhÆ° giÆ¡ tay, sá»­ dá»¥ng Ä‘iá»‡n thoáº¡i. YOLOv8 giÃºp nháº­n diá»‡n Ä‘á»‘i tÆ°á»£ng trong áº£nh/video theo thá»i gian thá»±c, há»— trá»£ giÃ¡o viÃªn quáº£n lÃ½ lá»›p há»c hiá»‡u quáº£ hÆ¡n. CÃ´ng nghá»‡ nÃ y giÃºp tÄƒng cÆ°á»ng sá»± tÆ°Æ¡ng tÃ¡c vÃ  giÃ¡m sÃ¡t, nÃ¢ng cao cháº¥t lÆ°á»£ng dáº¡y vÃ  há»c.
  Äá» tÃ i nÃ y sá»­ dá»¥ng model YOLOV8 Ä‘á»ƒ nháº­n diá»‡n hÃ nh vi há»c sinh vá»›i cÃ¡c hÃ nh vi nhÆ° giÆ¡ tay, cÃºi Ä‘áº§u, sá»­ dá»¥ng Ä‘iá»‡n thoáº¡i/mÃ¡y tÃ­nh. YOLOV8 ná»•i tiáº¿ng vá»›i chá»©c nÄƒng phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng vÃ  phÃ¢n loáº¡i cÃ¹ng lÃºc theo thá»i gian thá»±c, giÃºp giÃ¡o viÃªn quáº£n lÃ½ lá»›p há»c hiá»‡u quáº£ hÆ¡n. Bá»n em chá»n cÃ´ng ngháº¹ nÃ y Ä‘á»ƒ 


</p>

---

## ğŸŒŸ Giá»›i thiá»‡u
<p align="center">
  <img src="./anhimage/Flowchart.png" alt="Flowchart" width="800"/>
</p>

---
## ğŸ—ï¸ Há»† THá»NG
<p align="center">
  <img src="./anhimage/yolov8-comparison-plots.png" alt="System Architecture" width="800"/>
</p>

---


## ğŸ› ï¸ CÃ”NG NGHá»† Sá»¬ Dá»¤NG

<div align="center">

<p align="center">
  <img src="./anhimage/yolov8-comparison-plots.png" alt="System Architecture" width="800"/>
</p>
</div>

##  YÃªu cáº§u há»‡ thá»‘ng

-CÃ³ thá»ƒ sá»­ dá»¥ng Visual Studio Code náº¿u mÃ¡y cÃ³ GPU Ä‘á»§ máº¡nh
<br>
  hoáº·c lÃ 
<br>
-Sá»­ dá»¥ng <a href="https://colab.google/" target="_blank">Google Colab</a> há»— trá»£ cho dÃ¹ng miá»…n phÃ­ GPU Ä‘á»ƒ train model.

## ğŸš€ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  cháº¡y


## ğŸš€ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  cháº¡y mÃ´ hÃ¬nh YOLOv8

### BÆ°á»›c 1: Thu tháº­p dá»¯ liá»‡u
Sá»­ dá»¥ng dataset Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n sáºµn táº¡i mÃ´i trÆ°á»ng TrÆ°á»ng Äáº¡i há»c Äáº¡i Nam:

[ğŸ‘‰ Link Dataset](https://universe.roboflow.com/ttnt-nyz2m/ai-fxy4m/dataset/2)

### BÆ°á»›c 2: Sá»­ dá»¥ng Google Colab Ä‘á»ƒ Train mÃ´ hÃ¬nh
Truy cáº­p vÃ o Google Colab Ä‘á»ƒ thá»±c hiá»‡n huáº¥n luyá»‡n mÃ´ hÃ¬nh YOLOv8.

*LÆ°u Ã½: NÃªn sá»­ dá»¥ng Colab Pro Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh náº·ng hÆ¡n.*

```python
from google.colab import drive
drive.mount('/content/drive')
```

### BÆ°á»›c 3: CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
CÃ i Ä‘áº·t thÆ° viá»‡n vÃ  Ultralytics báº±ng cÃ¢u lá»‡nh sau:

```bash
!pip install ultralytics
```

### BÆ°á»›c 4: Huáº¥n luyá»‡n mÃ´ hÃ¬nh
Sá»­ dá»¥ng lá»‡nh dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh YOLOv8:

```bash
!python /content/yolov8/train.py \
    --data "/content/drive/MyDrive/BTL_AII/AI.v3-ai.yolov8pytorch/data.yaml" \
    --cfg "/content/yolov8/cfg/training/yolov8.yaml" \
    --weights "/content/SCB-dataset/yolov8/yolov8.pt" \
    --epochs 50 \
    --batch-size 16 \
    --img-size 640 \
    --device 0 \
    --workers 4 \
    --cache-images \
    --name Yolo7_BTL \
    --project "/content/drive/MyDrive/BTL_AII"
```
*LÆ°u Ã½: Chá»‰nh láº¡i cÃ¡c tham sá»‘ batch-size, workers phÃ¹ há»£p vá»›i cáº¥u hÃ¬nh GPU.*

### BÆ°á»›c 5: Nháº­n diá»‡n hÃ nh vi qua video
Download best.pt tá»« file weights cá»§a file káº¿t quáº£ train, rá»“i táº¡o file python Ä‘á»ƒ
cháº¡y mÃ´ hÃ¬nh YOLOv8 Ä‘á»ƒ nháº­n diá»‡n hÃ nh vi trong video sá»­ dá»¥ng webcam laptop vá»›i Ä‘oáº¡n mÃ£ sau:

```python

import cv2
import os
import time
from ultralytics import YOLO

# Load your custom YOLOv8 model
model = YOLO('D:/aiot/models/best (2).pt')  # Replace with the correct path to your model

# Create the 'detected_frames' directory if it doesn't exist
output_folder = 'detected_frames/final'
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# Open webcam (or video stream if needed)
cap = cv2.VideoCapture(0)  # Use 0 for default webcam, or provide the video stream path

if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

frame_count = 0  # Counter for naming saved frames
last_save_time = 0  # Thá»i Ä‘iá»ƒm lÆ°u áº£nh cuá»‘i cÃ¹ng

while True:
    ret, frame = cap.read()

    if not ret:
        print("Error: Could not read frame from webcam.")
        break

    # Perform object detection on the frame
    results = model(frame)

    # Kiá»ƒm tra náº¿u cÃ³ phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng
    if len(results) > 0:  # Äáº£m báº£o results khÃ´ng rá»—ng
        result = results[0]  # Láº¥y Ä‘á»‘i tÆ°á»£ng Results Ä‘áº§u tiÃªn
        if len(result.boxes) > 0:  # Kiá»ƒm tra náº¿u cÃ³ Ä‘á»‘i tÆ°á»£ng Ä‘Æ°á»£c phÃ¡t hiá»‡n
            # Render results (bounding boxes, labels, etc.)
            annotated_frame = result.plot()  # plot() tráº£ vá» frame Ä‘Ã£ Ä‘Æ°á»£c váº½

            # LÆ°u áº£nh náº¿u Ä‘Ã£ qua 1 giÃ¢y ká»ƒ tá»« láº§n lÆ°u trÆ°á»›c
            current_time = time.time()
            if current_time - last_save_time >= 1:  # Kiá»ƒm tra thá»i gian
                frame_filename = os.path.join(output_folder, f'frame_{frame_count:04d}.jpg')
                cv2.imwrite(frame_filename, annotated_frame)  # Save the frame as an image
                print(f"ÄÃ£ lÆ°u áº£nh: {frame_filename}")
                last_save_time = current_time  # Cáº­p nháº­t thá»i gian lÆ°u cuá»‘i cÃ¹ng
                frame_count += 1
        else:
            # Náº¿u khÃ´ng cÃ³ Ä‘á»‘i tÆ°á»£ng, dÃ¹ng frame gá»‘c Ä‘á»ƒ hiá»ƒn thá»‹
            annotated_frame = frame
    else:
        # Náº¿u khÃ´ng cÃ³ káº¿t quáº£, dÃ¹ng frame gá»‘c
        annotated_frame = frame

    # Display the annotated frame
    cv2.imshow('Live Stream Object Detection', annotated_frame)

    # Exit loop when 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release video capture and close window
cap.release()
cv2.destroyAllWindows()
```
Sau Ä‘Ã³ cÃ¡c frame nháº­n diá»‡n Ä‘Æ°á»£c bá»Ÿi mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c lÆ°u vÃ o folder detected_frames




## ğŸ¤ ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi 3 thÃ nh viÃªn:

| Há» vÃ  TÃªn                | Vai trÃ²                  |
|--------------------------|--------------------------|
| VÃµ VÄ©nh ThÃ¡i             | PhÃ¡t triá»ƒn toÃ n bá»™ mÃ£ nguá»“n,kiá»ƒm thá»­, triá»ƒn khai dá»± Ã¡n, thuyáº¿t trÃ¬nh, Ä‘á» xuáº¥t cáº£i tiáº¿n.|
| LÃª Ngá»c HÆ°ng            | Thá»±c hiá»‡n video giá»›i thiá»‡u|
| Pháº¡m Tiáº¿n DÅ©ng   | Viáº¿t bÃ¡o cÃ¡o.  |

Â© 2025 NHÃ“M 2, CNTT 16-01, TRÆ¯á»œNG Äáº I Há»ŒC Äáº I NAM
